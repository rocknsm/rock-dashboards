filter {
  if [client][ip] {
    # Make sure IP is valid, rfc check, private/public, and cleanup common things like preceeding "0" and or file share/path "\\"
    ruby {
      path => "/etc/logstash/ruby/logstash-ruby-filter-ip_clean_and_public.rb"
      script_params => {
        "parent_field" => "[client]"
        "ip" => "[client][ip]"
      }
      tag_on_exception =>  "_rubyexception-all-client_ip_clean_and_public"
    }

    # If still has valid IP(s) after cleanup
    if [client][ip] {
      # Update related IPs
      mutate { merge => { "[related][ip]" => "[client][ip]" } }
      #TODO:eventually support geo/asn on all IPs if array, right now just is only one (and not if first IP is private and second is public it will do on first one per doc on using logstash geoip plugin )
      if [@metadata][client][ip][number_of_ip_addresses] == 1 {
        if [client][ip_public] {

          # Geo Location
          geoip {
            source => "[client][ip]"
            target => "[client][geo]"
            default_database_type => "City"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][client_ip_geo_location_successful]" => "true" }
            fields => [ "city_name", "continent_code", "country_code2", "country_code3", "country_name", "dma_code", "latitude", "longitude", "postal_code", "region_name", "timezone" ]
            # Remove duplicate fields of location.lat & location.lon
            remove_field => [ "[client][geo][ip]" ]
          }
          # Rename geo location to correct fields if success
          if [@metadata][client_ip_geo_location_successful] {
            mutate { copy => { "[client][geo][country_code2]" => "[client][geo][country_iso_code]" } }
            #  mutate {
            #    merge => {
            #      "[related][geo]" => ["%{[client][geo][location][lat]},%{[client][geo][location][lon]}"]
            #    }
            #  }
          }

          # BGP AS name / BGP AS number / BGP autonomous system name&number
          geoip {
            source => "[client][ip]"
            target => "[client][as]"
            default_database_type => "ASN"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][client_ip_bgp_as_info_successful]" => "true" }
          }
          # Rename geo AS/ASN/BGP stuff to correct fields if success
          if [@metadata][client_ip_bgp_as_info_successful] {
            mutate {
              rename => {
                "[client][as][asn]" => "[client][as][number]"
                "[client][as][as_org]" => "[client][as][organization][name]"
              }
            }
          }
        }
      }
    }
  }

  if [server][ip] {
    # Make sure IP is valid and cleanup common things like preceeding "0"s or file share/path "\\"
    ruby {
      path => "/etc/logstash/ruby/logstash-ruby-filter-ip_clean_and_public.rb"
      script_params => {
        "parent_field" => "[server]"
        "ip" => "[server][ip]"
      }
      tag_on_exception =>  "_rubyexception-all-server_ip_clean_and_public"
    }

    # If still has valid IP(s) after cleanup
    if [server][ip] {

      # Update related IPs
      mutate { merge => { "[related][ip]" => "[server][ip]" } }
      #TODO:eventually support geo/asn on all IPs if array, right now just is only one (and not if first IP is private and second is. zDamTyILGeKD4H0.IbPK6g... public it will do on first one per doc on using logstash geoip plugin )
      if [@metadata][server][ip][number_of_ip_addresses] == 1 {
        if [server][ip_public] {
          geoip {
            source => "[server][ip]"
            target => "[server][geo]"
            default_database_type => "City"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][server_ip_geo_location_successful]" => "true" }
            fields => [ "city_name", "continent_code", "country_code2", "country_code3", "country_name", "dma_code", "latitude", "longitude", "postal_code", "region_name", "timezone" ]
            # Remove duplicate fields of location.lat & location.lon
            remove_field => [ "[server][geo][ip]" ]
          }
          # Rename geo location stuff to correct fields if success
          if [@metadata][server_ip_geo_location_successful] {
            mutate { copy => { "[server][geo][country_code2]" => "[server][geo][country_iso_code]" } }
            #  mutate {
            #    merge => {
            #      "[related][geo]" => ["%{[server][geo][location][lat]},%{[server][geo][location][lon]}"]
            #    }
            #  }
          }
          geoip {
            source => "[server][ip]"
            target => "[server][as]"
            default_database_type => "ASN"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][server_ip_bgp_as_info_successful]" => "true" }
          }
          # Rename geo AS/ASN/BGP stuff to correct fields if success
          if [@metadata][server_ip_bgp_as_info_successful] {
            mutate {
              rename => {
                "[server][as][asn]" => "[server][as][number]"
                "[server][as][as_org]" => "[server][as][organization][name]"
              }
            }
          }
        }
      }
    }
  }

  if [source][ip] {
    # Make sure IP is valid and cleanup common things like preceeding "0"s or file share/path "\\"
    ruby {
      path => "/etc/logstash/ruby/logstash-ruby-filter-ip_clean_and_public.rb"
      script_params => {
        "parent_field" => "[source]"
        "ip" => "[source][ip]"
      }
      tag_on_exception =>  "_rubyexception-all-source_ip_clean_and_public"
    }

    # If still has valid IP(s) after cleanup
    if [source][ip] {

      # Update related IPs
      mutate { merge => { "[related][ip]" => "[source][ip]" } }
      #TODO:eventually support geo/asn on all IPs if array, right now just is only one (and not if first IP is private and second is public it will do on first one per doc on using logstash geoip plugin )
      if [@metadata][source][ip][number_of_ip_addresses] == 1 {
        if [source][ip_public] {
          geoip {
            source => "[source][ip]"
            target => "[source][geo]"
            default_database_type => "City"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][source_ip_geo_location_successful]" => "true" }
            fields => [ "city_name", "continent_code", "country_code2", "country_code3", "country_name", "dma_code", "latitude", "longitude", "postal_code", "region_name", "timezone" ]
            # Remove duplicate fields of location.lat & location.lon
            remove_field => [ "[source][geo][ip]" ]
          }
          # Rename geo location stuff to correct fields if success
          if [@metadata][source_ip_geo_location_successful] {
            mutate { copy => { "[source][geo][country_code2]" => "[source][geo][country_iso_code]" } }
            #  mutate {
            #    merge => {
            #      "[related][geo]" => ["%{[source][geo][location][lat]},%{[source][geo][location][lon]}"]
            #    }
            #  }
          }
          geoip {
            source => "[source][ip]"
            target => "[source][as]"
            default_database_type => "ASN"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][source_ip_bgp_as_info_successful]" => "true" }
          }
          # Rename geo AS/ASN/BGP stuff to correct fields if success
          if [@metadata][source_ip_bgp_as_info_successful] {
            mutate {
              rename => {
                "[source][as][asn]" => "[source][as][number]"
                "[source][as][as_org]" => "[source][as][organization][name]"
              }
            }
          }
        }
      }
    }
  }

  if [destination][ip] {
    # Make sure IP is valid and cleanup common things like preceeding "0"s or file share/path "\\"
    ruby {
      path => "/etc/logstash/ruby/logstash-ruby-filter-ip_clean_and_public.rb"
      script_params => {
        "parent_field" => "[destination]"
        "ip" => "[destination][ip]"
      }
      tag_on_exception =>  "_rubyexception-all-destination_ip_clean_and_public"
    }

    # If still has valid IP(s) after cleanup
    if [destination][ip] {

      # Update related IPs
      mutate { merge => { "[related][ip]" => "[destination][ip]" } }
      #TODO:eventually support geo/asn on all IPs if array, right now just is only one (and not if first IP is private and second is public it will do on first one per doc on using logstash geoip plugin )
      if [@metadata][destination][ip][number_of_ip_addresses] == 1 {
        if [destination][ip_public] {
          geoip {
            source => "[destination][ip]"
            target => "[destination][geo]"
            default_database_type => "City"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][destination_ip_geo_location_successful]" => "true" }
            fields => [ "city_name", "continent_code", "country_code2", "country_code3", "country_name", "dma_code", "latitude", "longitude", "postal_code", "region_name", "timezone" ]
            # Remove duplicate fields of location.lat & location.lon
            remove_field => [ "[destination][geo][ip]" ]
          }
          # Rename geo location stuff to correct fields if success
          if [@metadata][destination_ip_geo_location_successful] {
            mutate { copy => { "[destination][geo][country_code2]" => "[destination][geo][country_iso_code]" } }
            #  mutate {
            #    merge => {
            #      "[related][geo]" => ["%{[destination][geo][location][lat]},%{[destination][geo][location][lon]}"]
            #    }
            #  }
          }
          geoip {
            source => "[destination][ip]"
            target => "[destination][as]"
            default_database_type => "ASN"
            # #TONOTE:It is important to note that this config value is global to the geoip_type. That is to say all instances of the geoip filter of the same geoip_type share the same cache. The last declared cache size will win. The reason for this is that there would be no benefit to having multiple caches for different instances at different points in the pipeline, that would just increase the number of cache misses and waste memory.
            cache_size => 90000
            add_field =>  { "[@metadata][destination_ip_bgp_as_info_successful]" => "true" }
          }
          # Rename geo AS/ASN/BGP stuff to correct fields if success
          if [@metadata][destination_ip_bgp_as_info_successful] {
            mutate {
              rename => {
                "[destination][as][asn]" => "[destination][as][number]"
                "[destination][as][as_org]" => "[destination][as][organization][name]"
              }
            }
          }
        }
      }
    }
  }
}
